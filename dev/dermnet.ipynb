{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset into a DataFrame\n",
    "base_dir = '../data-collection/dataset/data'\n",
    "\n",
    "# Load the disease classification DataFrame\n",
    "classification_df = pd.read_csv('../data-collection/dataset/disease_classification.csv')\n",
    "classification_df.columns = ['disease_name', 'effect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset function\n",
    "def prepare_dataset(base_dir):\n",
    "    records = []\n",
    "    for disease_name in os.listdir(base_dir):\n",
    "        disease_dir = os.path.join(base_dir, disease_name)\n",
    "        if os.path.isdir(disease_dir):\n",
    "            for body_part in os.listdir(disease_dir):\n",
    "                body_part_dir = os.path.join(disease_dir, body_part)\n",
    "                if os.path.isdir(body_part_dir):\n",
    "                    for image_name in os.listdir(body_part_dir):\n",
    "                        image_path = os.path.join(body_part_dir, image_name)\n",
    "                        if os.path.isfile(image_path):\n",
    "                            records.append([disease_name, body_part, image_name, image_path])\n",
    "    df = pd.DataFrame(records, columns=['disease_name', 'body_part', 'image_name', 'image_path'])\n",
    "    return df\n",
    "\n",
    "# Load the dataset\n",
    "df = prepare_dataset(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the datasets to add the 'effect' column\n",
    "df = df.merge(classification_df, on='disease_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'disease_present' column\n",
    "df['disease_present'] = df['disease_name'] != 'normal_skin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "le_disease = LabelEncoder()\n",
    "df['disease_label'] = le_disease.fit_transform(df['disease_name'])\n",
    "\n",
    "le_effect = LabelEncoder()\n",
    "df['effect_label'] = le_effect.fit_transform(df['effect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_df = df.sample(frac=0.8, random_state=42)\n",
    "val_df = df.drop(train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image normalization and augmentation\n",
    "def preprocess_input(img):\n",
    "    mean = np.array([123.68, 116.779, 103.939])  # Mean RGB values for ImageNet\n",
    "    return (img - mean) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],  # Brightness adjustment\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3137 validated image filenames.\n",
      "Found 784 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Prepare data generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, x_col='image_path', y_col='disease_label',\n",
    "    target_size=(224, 224), batch_size=32, class_mode='raw'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    val_df, x_col='image_path', y_col='disease_label',\n",
    "    target_size=(224, 224), batch_size=32, class_mode='raw'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple CNN model for demonstration\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    \n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    tf.keras.layers.Dense(len(le_disease.classes_), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prais\\.conda\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a ModelCheckpoint callback to save the best model during training\n",
    "checkpoint = ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "99/99 [==============================] - ETA: 0s - loss: 4.7700 - accuracy: 0.0300\n",
      "Epoch 1: val_accuracy improved from -inf to 0.02551, saving model to best_model.h5\n",
      "99/99 [==============================] - 36s 293ms/step - loss: 4.7700 - accuracy: 0.0300 - val_loss: 4.7599 - val_accuracy: 0.0255\n",
      "Epoch 2/10\n",
      "99/99 [==============================] - ETA: 0s - loss: 4.5207 - accuracy: 0.0529\n",
      "Epoch 2: val_accuracy improved from 0.02551 to 0.03571, saving model to best_model.h5\n",
      "99/99 [==============================] - 26s 259ms/step - loss: 4.5207 - accuracy: 0.0529 - val_loss: 4.6288 - val_accuracy: 0.0357\n",
      "Epoch 3/10\n",
      "99/99 [==============================] - ETA: 0s - loss: 4.3512 - accuracy: 0.0653\n",
      "Epoch 3: val_accuracy improved from 0.03571 to 0.04209, saving model to best_model.h5\n",
      "99/99 [==============================] - 25s 250ms/step - loss: 4.3512 - accuracy: 0.0653 - val_loss: 4.5439 - val_accuracy: 0.0421\n",
      "Epoch 4/10\n",
      "99/99 [==============================] - ETA: 0s - loss: 4.2737 - accuracy: 0.0692\n",
      "Epoch 4: val_accuracy improved from 0.04209 to 0.05995, saving model to best_model.h5\n",
      "99/99 [==============================] - 25s 251ms/step - loss: 4.2737 - accuracy: 0.0692 - val_loss: 4.4672 - val_accuracy: 0.0599\n",
      "Epoch 5/10\n",
      "99/99 [==============================] - ETA: 0s - loss: 4.2014 - accuracy: 0.0803\n",
      "Epoch 5: val_accuracy improved from 0.05995 to 0.07398, saving model to best_model.h5\n",
      "99/99 [==============================] - 27s 268ms/step - loss: 4.2014 - accuracy: 0.0803 - val_loss: 4.3615 - val_accuracy: 0.0740\n",
      "Epoch 6/10\n",
      "99/99 [==============================] - ETA: 0s - loss: 4.1509 - accuracy: 0.0768\n",
      "Epoch 6: val_accuracy improved from 0.07398 to 0.08163, saving model to best_model.h5\n",
      "99/99 [==============================] - 26s 258ms/step - loss: 4.1509 - accuracy: 0.0768 - val_loss: 4.2424 - val_accuracy: 0.0816\n",
      "Epoch 7/10\n",
      "99/99 [==============================] - ETA: 0s - loss: 4.1027 - accuracy: 0.0851\n",
      "Epoch 7: val_accuracy improved from 0.08163 to 0.08929, saving model to best_model.h5\n",
      "99/99 [==============================] - 28s 280ms/step - loss: 4.1027 - accuracy: 0.0851 - val_loss: 4.1661 - val_accuracy: 0.0893\n",
      "Epoch 8/10\n",
      "99/99 [==============================] - ETA: 0s - loss: 4.0713 - accuracy: 0.0835\n",
      "Epoch 8: val_accuracy did not improve from 0.08929\n",
      "99/99 [==============================] - 29s 296ms/step - loss: 4.0713 - accuracy: 0.0835 - val_loss: 4.1331 - val_accuracy: 0.0855\n",
      "Epoch 9/10\n",
      "99/99 [==============================] - ETA: 0s - loss: 4.0517 - accuracy: 0.0912\n",
      "Epoch 9: val_accuracy improved from 0.08929 to 0.09566, saving model to best_model.h5\n",
      "99/99 [==============================] - 27s 270ms/step - loss: 4.0517 - accuracy: 0.0912 - val_loss: 4.1191 - val_accuracy: 0.0957\n",
      "Epoch 10/10\n",
      "99/99 [==============================] - ETA: 0s - loss: 4.0091 - accuracy: 0.0928\n",
      "Epoch 10: val_accuracy did not improve from 0.09566\n",
      "99/99 [==============================] - 27s 272ms/step - loss: 4.0091 - accuracy: 0.0928 - val_loss: 4.1081 - val_accuracy: 0.0906\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_generator, validation_data=val_generator, epochs=10, batch_size=32, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 2s 71ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(val_generator)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.021683673469387755\n",
      "Precision: 0.010656838499653902\n",
      "Recall: 0.021683673469387755\n",
      "F1 Score: 0.0113566972000564\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.00      0.00      0.00         8\n",
      "           5       0.00      0.00      0.00        14\n",
      "           6       0.00      0.00      0.00         9\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         3\n",
      "          10       0.00      0.00      0.00         4\n",
      "          12       0.00      0.00      0.00        14\n",
      "          13       0.00      0.00      0.00         3\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.25      0.08      0.12        12\n",
      "          17       0.00      0.00      0.00        11\n",
      "          18       0.00      0.00      0.00         4\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00        11\n",
      "          21       0.00      0.00      0.00         5\n",
      "          22       0.00      0.00      0.00         3\n",
      "          24       0.00      0.00      0.00         6\n",
      "          25       0.00      0.00      0.00         7\n",
      "          26       0.00      0.00      0.00         6\n",
      "          28       0.00      0.00      0.00         1\n",
      "          30       0.00      0.00      0.00         5\n",
      "          32       0.00      0.00      0.00         4\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00        11\n",
      "          35       0.04      0.17      0.06        24\n",
      "          36       0.06      0.12      0.08         8\n",
      "          37       0.00      0.00      0.00         7\n",
      "          38       0.00      0.00      0.00         4\n",
      "          39       0.00      0.00      0.00        13\n",
      "          40       0.00      0.00      0.00         5\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.00      0.00      0.00         5\n",
      "          43       0.00      0.00      0.00         8\n",
      "          45       0.00      0.00      0.00         2\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00         9\n",
      "          50       0.00      0.00      0.00         4\n",
      "          51       0.00      0.00      0.00         7\n",
      "          52       0.00      0.00      0.00         5\n",
      "          54       0.05      0.06      0.06        33\n",
      "          56       0.00      0.00      0.00         2\n",
      "          57       0.00      0.00      0.00         3\n",
      "          59       0.00      0.00      0.00        10\n",
      "          60       0.00      0.00      0.00        16\n",
      "          61       0.00      0.00      0.00        15\n",
      "          62       0.00      0.00      0.00         8\n",
      "          63       0.00      0.00      0.00        10\n",
      "          64       0.00      0.00      0.00         1\n",
      "          65       0.01      0.05      0.02        20\n",
      "          66       0.00      0.00      0.00         6\n",
      "          67       0.00      0.00      0.00        10\n",
      "          68       0.00      0.00      0.00         2\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.00      0.00      0.00         6\n",
      "          73       0.00      0.00      0.00         1\n",
      "          75       0.04      0.25      0.07        16\n",
      "          76       0.00      0.00      0.00        18\n",
      "          77       0.00      0.00      0.00         2\n",
      "          78       0.00      0.00      0.00         6\n",
      "          80       0.00      0.00      0.00         4\n",
      "          81       0.00      0.00      0.00         6\n",
      "          82       0.04      0.08      0.05        26\n",
      "          85       0.00      0.00      0.00         1\n",
      "          86       0.00      0.00      0.00         2\n",
      "          87       0.00      0.00      0.00         1\n",
      "          88       0.00      0.00      0.00         2\n",
      "          89       0.00      0.00      0.00         3\n",
      "          90       0.00      0.00      0.00         8\n",
      "          91       0.00      0.00      0.00        11\n",
      "          92       0.00      0.00      0.00         1\n",
      "          93       0.00      0.00      0.00         2\n",
      "          94       0.00      0.00      0.00         6\n",
      "          95       0.00      0.00      0.00         6\n",
      "          96       0.00      0.00      0.00         3\n",
      "          97       0.00      0.00      0.00         9\n",
      "          98       0.00      0.00      0.00        11\n",
      "          99       0.00      0.00      0.00        16\n",
      "         100       0.00      0.00      0.00         2\n",
      "         101       0.00      0.00      0.00         7\n",
      "         102       0.00      0.00      0.00         1\n",
      "         103       0.00      0.00      0.00         4\n",
      "         104       0.00      0.00      0.00         7\n",
      "         105       0.00      0.00      0.00         1\n",
      "         106       0.00      0.00      0.00        14\n",
      "         107       0.00      0.00      0.00         3\n",
      "         108       0.01      0.08      0.02        13\n",
      "         109       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00        10\n",
      "         111       0.00      0.00      0.00        21\n",
      "         112       0.01      0.08      0.02        12\n",
      "         113       0.00      0.00      0.00         6\n",
      "         114       0.00      0.00      0.00        11\n",
      "         115       0.00      0.00      0.00         1\n",
      "         116       0.00      0.00      0.00         1\n",
      "         117       0.00      0.00      0.00         4\n",
      "         118       0.00      0.00      0.00         3\n",
      "         119       0.00      0.00      0.00        10\n",
      "         120       0.00      0.00      0.00         1\n",
      "         121       0.00      0.00      0.00        20\n",
      "         122       0.00      0.00      0.00        11\n",
      "         123       0.00      0.00      0.00         5\n",
      "         124       0.00      0.00      0.00         3\n",
      "         125       0.00      0.00      0.00         5\n",
      "         126       0.00      0.00      0.00        24\n",
      "         127       0.00      0.00      0.00         6\n",
      "         128       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.02       784\n",
      "   macro avg       0.00      0.01      0.00       784\n",
      "weighted avg       0.01      0.02      0.01       784\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prais\\.conda\\envs\\tensorflow_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\prais\\.conda\\envs\\tensorflow_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\prais\\.conda\\envs\\tensorflow_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\prais\\.conda\\envs\\tensorflow_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_true = val_df['disease_label'].values\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred_classes))\n",
    "print(\"Precision:\", precision_score(y_true, y_pred_classes, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_true, y_pred_classes, average='weighted'))\n",
    "print(\"F1 Score:\", f1_score(y_true, y_pred_classes, average='weighted'))\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
